{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10973603,"sourceType":"datasetVersion","datasetId":6828356}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install huggingface_hub\n","metadata":{"id":"nNS3MM3WUYld","outputId":"64e0d342-327c-4922-a091-8f21f5b29964","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:04:37.783322Z","iopub.execute_input":"2025-03-10T15:04:37.783585Z","iopub.status.idle":"2025-03-10T15:04:42.025741Z","shell.execute_reply.started":"2025-03-10T15:04:37.783557Z","shell.execute_reply":"2025-03-10T15:04:42.024866Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.29.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.12.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2025.1.31)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!huggingface-cli login --token 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","metadata":{"id":"BvLu9OFEUe8P","outputId":"533f80df-b027-4a17-8b9d-d6b6e2d78851","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:04:42.027505Z","iopub.execute_input":"2025-03-10T15:04:42.027862Z","iopub.status.idle":"2025-03-10T15:04:42.908423Z","shell.execute_reply.started":"2025-03-10T15:04:42.027836Z","shell.execute_reply":"2025-03-10T15:04:42.907417Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nThe token `EECS6895` has been saved to /root/.cache/huggingface/stored_tokens\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful.\nThe current active token is: `EECS6895`\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install faiss-cpu","metadata":{"id":"3AL3PT8BSTsT","outputId":"bea77a68-1da3-47c9-a97f-5571e4d079ce","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:04:42.910107Z","iopub.execute_input":"2025-03-10T15:04:42.910340Z","iopub.status.idle":"2025-03-10T15:04:47.816656Z","shell.execute_reply.started":"2025-03-10T15:04:42.910320Z","shell.execute_reply":"2025-03-10T15:04:47.815837Z"}},"outputs":[{"name":"stdout","text":"Collecting faiss-cpu\n  Downloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nDownloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (30.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.10.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install -U langchain-community","metadata":{"id":"aPcyUtTQdwxQ","outputId":"0f989ada-bb04-45af-f996-a9025adb15ee","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:04:47.817585Z","iopub.execute_input":"2025-03-10T15:04:47.817858Z","iopub.status.idle":"2025-03-10T15:04:56.795061Z","shell.execute_reply.started":"2025-03-10T15:04:47.817833Z","shell.execute_reply":"2025-03-10T15:04:56.794228Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain-community\n  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\nCollecting langchain-core<1.0.0,>=0.3.41 (from langchain-community)\n  Downloading langchain_core-0.3.43-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain<1.0.0,>=0.3.20 (from langchain-community)\n  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.12)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nCollecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain<1.0.0,>=0.3.20->langchain-community)\n  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<1.0.0,>=0.3.20->langchain-community) (2.11.0a2)\nCollecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.12)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2.4.1)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain-community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain-community) (2.29.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.26.2->langchain-community) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.2.2)\nDownloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain-0.3.20-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.43-py3-none-any.whl (415 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.4/415.4 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\nDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\nDownloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\nDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\nInstalling collected packages: python-dotenv, httpx-sse, async-timeout, pydantic-settings, langchain-core, langchain-text-splitters, langchain, langchain-community\n  Attempting uninstall: async-timeout\n    Found existing installation: async-timeout 5.0.1\n    Uninstalling async-timeout-5.0.1:\n      Successfully uninstalled async-timeout-5.0.1\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.25\n    Uninstalling langchain-core-0.3.25:\n      Successfully uninstalled langchain-core-0.3.25\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.3\n    Uninstalling langchain-text-splitters-0.3.3:\n      Successfully uninstalled langchain-text-splitters-0.3.3\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.12\n    Uninstalling langchain-0.3.12:\n      Successfully uninstalled langchain-0.3.12\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed async-timeout-4.0.3 httpx-sse-0.4.0 langchain-0.3.20 langchain-community-0.3.19 langchain-core-0.3.43 langchain-text-splitters-0.3.6 pydantic-settings-2.8.1 python-dotenv-1.0.1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import sys\nimport subprocess\n\ndef install_package(package):\n    try:\n        __import__(package)\n    except ImportError:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])","metadata":{"id":"MzrEPpQp0qgc","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:04:56.795832Z","iopub.execute_input":"2025-03-10T15:04:56.796106Z","iopub.status.idle":"2025-03-10T15:04:56.800426Z","shell.execute_reply.started":"2025-03-10T15:04:56.796083Z","shell.execute_reply":"2025-03-10T15:04:56.799642Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"for package in [\"gensim\", \"pyLDAvis\", \"nltk\", \"matplotlib\", \"pandas\", \"bitsandbytes\"]:\n    install_package(package)\n\nimport numpy as np\nimport faiss\nfrom bitsandbytes.functional import quantize_4bit\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\nfrom peft import PeftModel\nimport torch\nfrom collections import Counter\nfrom sklearn.cluster import KMeans\nfrom google.colab import drive\nfrom langchain.document_loaders import TextLoader\nimport gensim\nfrom gensim import corpora\nfrom gensim.models import LdaModel\nimport nltk\nfrom nltk.tokenize import word_tokenize\nimport matplotlib.pyplot as plt\nimport pyLDAvis\nimport pyLDAvis.gensim_models\nimport pandas as pd","metadata":{"id":"S4PNsYXV0rEw","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:04:56.801320Z","iopub.execute_input":"2025-03-10T15:04:56.801626Z","iopub.status.idle":"2025-03-10T15:05:38.910525Z","shell.execute_reply.started":"2025-03-10T15:04:56.801594Z","shell.execute_reply":"2025-03-10T15:05:38.909634Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/nltk/decorators.py:69: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n  signature = inspect.formatargspec(regargs, varargs, varkwargs, defaults,\n/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/util.py:55: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs; see https://jax.readthedocs.io/en/latest/aot.html. For example, replace xla_computation(f)(*xs) with jit(f).lower(*xs).compiler_ir('hlo'). See CHANGELOG.md for 0.4.30 for more examples.\n  from jax import xla_computation as _xla_computation\n/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/util.py:55: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs; see https://jax.readthedocs.io/en/latest/aot.html. For example, replace xla_computation(f)(*xs) with jit(f).lower(*xs).compiler_ir('hlo'). See CHANGELOG.md for 0.4.30 for more examples.\n  from jax import xla_computation as _xla_computation\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# 1. Load German Credit（UCI database）\nurl_german = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\ncolumn_names = [\"Status of existing checking account\", \"Duration in month\", \"Credit history\",\n                \"Purpose\", \"Credit amount\", \"Savings account/bonds\", \"Present employment since\",\n                \"Installment rate in percentage of disposable income\", \"Personal status and sex\",\n                \"Other debtors / guarantors\", \"Present residence since\", \"Property\",\n                \"Age in years\", \"Other installment plans\", \"Housing\", \"Number of existing credits at this bank\",\n                \"Job\", \"Number of people being liable to provide maintenance for\", \"Telephone\", \"Foreign worker\", \"Credit risk\"]\ngerman_credit = pd.read_csv(url_german, delimiter=' ', header=None, names=column_names)\n\n# 2. Load Credit Card Fraud（Kaggle）\nurl_fraud = \"../input/credit-scoring-tabular/creditcard.csv\"\ncredit_card_fraud = pd.read_csv(url_fraud)\n\n# Descriptive Summary\nprint(\"German Credit Dataset:\")\nprint(german_credit.head())\nprint(\"Credit Card Fraud Dataset:\")\nprint(credit_card_fraud.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:38.911433Z","iopub.execute_input":"2025-03-10T15:05:38.911734Z","iopub.status.idle":"2025-03-10T15:05:41.957335Z","shell.execute_reply.started":"2025-03-10T15:05:38.911700Z","shell.execute_reply":"2025-03-10T15:05:41.956322Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n","output_type":"stream"},{"name":"stdout","text":"German Credit Dataset:\n  Status of existing checking account  Duration in month Credit history  \\\n0                                 A11                  6            A34   \n1                                 A12                 48            A32   \n2                                 A14                 12            A34   \n3                                 A11                 42            A32   \n4                                 A11                 24            A33   \n\n  Purpose  Credit amount Savings account/bonds Present employment since  \\\n0     A43           1169                   A65                      A75   \n1     A43           5951                   A61                      A73   \n2     A46           2096                   A61                      A74   \n3     A42           7882                   A61                      A74   \n4     A40           4870                   A61                      A73   \n\n   Installment rate in percentage of disposable income  \\\n0                                                  4     \n1                                                  2     \n2                                                  2     \n3                                                  2     \n4                                                  3     \n\n  Personal status and sex Other debtors / guarantors  ...  Property  \\\n0                     A93                       A101  ...      A121   \n1                     A92                       A101  ...      A121   \n2                     A93                       A101  ...      A121   \n3                     A93                       A103  ...      A122   \n4                     A93                       A101  ...      A124   \n\n  Age in years  Other installment plans Housing  \\\n0           67                     A143    A152   \n1           22                     A143    A152   \n2           49                     A143    A152   \n3           45                     A143    A153   \n4           53                     A143    A153   \n\n  Number of existing credits at this bank   Job  \\\n0                                       2  A173   \n1                                       1  A173   \n2                                       1  A172   \n3                                       1  A173   \n4                                       2  A173   \n\n  Number of people being liable to provide maintenance for  Telephone  \\\n0                                                  1             A192   \n1                                                  1             A191   \n2                                                  2             A191   \n3                                                  2             A191   \n4                                                  2             A191   \n\n  Foreign worker Credit risk  \n0           A201           1  \n1           A201           2  \n2           A201           1  \n3           A201           1  \n4           A201           2  \n\n[5 rows x 21 columns]\nCredit Card Fraud Dataset:\n   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"status_checking_account_mapping = {\n    \"A11\": \"< 0 DM\",\n    \"A12\": \"0 <= ... < 200 DM\",\n    \"A13\": \">= 200 DM / salary assignments for at least 1 year\",\n    \"A14\": \"No checking account\"\n}\n\ncredit_history_mapping = {\n    \"A30\": \"No credits taken/ all credits paid back duly\",\n    \"A31\": \"All credits at this bank paid back duly\",\n    \"A32\": \"Existing credits paid back duly till now\",\n    \"A33\": \"Delay in paying off in the past\",\n    \"A34\": \"Critical account/ other credits existing (not at this bank)\"\n}\n\npurpose_mapping = {\n    \"A40\": \"Car (new)\",\n    \"A41\": \"Car (used)\",\n    \"A42\": \"Furniture/equipment\",\n    \"A43\": \"Radio/television\",\n    \"A44\": \"Domestic appliances\",\n    \"A45\": \"Repairs\",\n    \"A46\": \"Education\",\n    \"A47\": \"Vacation\",\n    \"A48\": \"Retraining\",\n    \"A49\": \"Business\",\n    \"A410\": \"Others\"\n}\n\nsavings_account_mapping = {\n    \"A61\": \"< 100 DM\",\n    \"A62\": \"100 <= ... < 500 DM\",\n    \"A63\": \"500 <= ... < 1000 DM\",\n    \"A64\": \">= 1000 DM\",\n    \"A65\": \"Unknown/No savings account\"\n}\n\nemployment_mapping = {\n    \"A71\": \"Unemployed\",\n    \"A72\": \"< 1 year\",\n    \"A73\": \"1 <= ... < 4 years\",\n    \"A74\": \"4 <= ... < 7 years\",\n    \"A75\": \">= 7 years\"\n}\n\npersonal_status_mapping = {\n    \"A91\": \"Male: divorced/separated\",\n    \"A92\": \"Female: divorced/separated/married\",\n    \"A93\": \"Male: single\",\n    \"A94\": \"Male: married/widowed\",\n    \"A95\": \"Female: single\"\n}\n\nother_debtors_mapping = {\n    \"A101\": \"None\",\n    \"A102\": \"Co-applicant\",\n    \"A103\": \"Guarantor\"\n}\n\nproperty_mapping = {\n    \"A121\": \"Real estate\",\n    \"A122\": \"Building society savings agreement/life insurance\",\n    \"A123\": \"Car or other (not in attribute 6)\",\n    \"A124\": \"Unknown/No property\"\n}\n\ninstallment_plans_mapping = {\n    \"A141\": \"Bank\",\n    \"A142\": \"Stores\",\n    \"A143\": \"None\"\n}\n\nhousing_mapping = {\n    \"A151\": \"Rent\",\n    \"A152\": \"Own\",\n    \"A153\": \"For free\"\n}\n\njob_mapping = {\n    \"A171\": \"Unemployed/unskilled - non-resident\",\n    \"A172\": \"Unskilled - resident\",\n    \"A173\": \"Skilled employee/official\",\n    \"A174\": \"Management/self-employed/highly qualified employee/officer\"\n}\n\ntelephone_mapping = {\n    \"A191\": \"None\",\n    \"A192\": \"Yes, registered under the customer's name\"\n}\n\nforeign_worker_mapping = {\n    \"A201\": \"Yes\",\n    \"A202\": \"No\"\n}\n\n# combine\ncombined_mapping = {\n    **status_checking_account_mapping,\n    **credit_history_mapping,\n    **purpose_mapping,\n    **savings_account_mapping,\n    **employment_mapping,\n    **personal_status_mapping,\n    **other_debtors_mapping,\n    **property_mapping,\n    **installment_plans_mapping,\n    **housing_mapping,\n    **job_mapping,\n    **telephone_mapping,\n    **foreign_worker_mapping\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:41.958460Z","iopub.execute_input":"2025-03-10T15:05:41.958850Z","iopub.status.idle":"2025-03-10T15:05:41.966298Z","shell.execute_reply.started":"2025-03-10T15:05:41.958814Z","shell.execute_reply":"2025-03-10T15:05:41.965454Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# test\ngerman_credit_sample = german_credit.iloc[0].to_dict()\ncredit_card_fraud_sample = credit_card_fraud.iloc[0].to_dict()\ndef map_feature(value):\n    return combined_mapping.get(value, value) \n# Description-Based Prompt（German Credit）\ndef create_description_based_prompt(attributes):\n    prompt = \"### Description-Based Prompt (Credit Scoring)\\n\"\n    prompt += \"Task: Credit Scoring\\n\"\n    prompt += (\n        f\"A loan applicant with a checking account status of {map_feature(attributes['Status of existing checking account'])}, \"\n        f\"a credit history of {map_feature(attributes['Credit history'])}, and a loan purpose of {map_feature(attributes['Purpose'])}, \"\n        f\"has applied for a loan amount of {attributes['Credit amount']} with a duration of {attributes['Duration in month']} months.\\n\"\n        f\"The applicant is {attributes['Age in years']} years old, with a job status of {map_feature(attributes['Job'])} and \"\n        f\"an installment rate of {attributes['Installment rate in percentage of disposable income']}%.\\n\"\n        f\"Should this loan be approved?\\n\"\n    )\n    prompt += \"Choices: ['Approved', 'Denied']\\n\"\n    prompt += f\"Output: {'Approved' if attributes['Credit risk'] == 1 else 'Denied'}\\n\"\n    prompt += f\"Gold: {attributes['Credit risk']}\\n\"\n    prompt += \"\\n\"\n    return prompt\n\n# Table-Based Prompt（Credit Card Fraud）\ndef create_table_based_prompt(attributes):\n    prompt = \"### Table-Based Prompt (Fraud Detection)\\n\"\n    prompt += \"Task: Fraud Detection\\n\"\n    prompt += \"Attributes:\\n\"\n    for key, value in attributes.items():\n        prompt += f\"  {key}: {value}\\n\"\n    prompt += \"Question: Is this transaction fraudulent? (Yes/No)\\n\"\n    prompt += \"Choices: ['Yes', 'No']\\n\"\n    prompt += f\"Output: {'Yes' if attributes['Class'] == 1 else 'No'}\\n\"\n    prompt += f\"Gold: {attributes['Class']}\\n\"\n    prompt += \"\\n\"\n    return prompt\n\n# example\ndescription_based_prompt = create_description_based_prompt(german_credit_sample)\ntable_based_prompt = create_table_based_prompt(credit_card_fraud_sample)\n\nprint(description_based_prompt)\nprint(table_based_prompt)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:41.969835Z","iopub.execute_input":"2025-03-10T15:05:41.970058Z","iopub.status.idle":"2025-03-10T15:05:42.055283Z","shell.execute_reply.started":"2025-03-10T15:05:41.970039Z","shell.execute_reply":"2025-03-10T15:05:42.054196Z"}},"outputs":[{"name":"stdout","text":"### Description-Based Prompt (Credit Scoring)\nTask: Credit Scoring\nA loan applicant with a checking account status of < 0 DM, a credit history of Critical account/ other credits existing (not at this bank), and a loan purpose of Radio/television, has applied for a loan amount of 1169 with a duration of 6 months.\nThe applicant is 67 years old, with a job status of Skilled employee/official and an installment rate of 4%.\nShould this loan be approved?\nChoices: ['Approved', 'Denied']\nOutput: Approved\nGold: 1\n\n\n### Table-Based Prompt (Fraud Detection)\nTask: Fraud Detection\nAttributes:\n  Time: 0.0\n  V1: -1.3598071336738\n  V2: -0.0727811733098497\n  V3: 2.53634673796914\n  V4: 1.37815522427443\n  V5: -0.338320769942518\n  V6: 0.462387777762292\n  V7: 0.239598554061257\n  V8: 0.0986979012610507\n  V9: 0.363786969611213\n  V10: 0.0907941719789316\n  V11: -0.551599533260813\n  V12: -0.617800855762348\n  V13: -0.991389847235408\n  V14: -0.311169353699879\n  V15: 1.46817697209427\n  V16: -0.470400525259478\n  V17: 0.207971241929242\n  V18: 0.0257905801985591\n  V19: 0.403992960255733\n  V20: 0.251412098239705\n  V21: -0.018306777944153\n  V22: 0.277837575558899\n  V23: -0.110473910188767\n  V24: 0.0669280749146731\n  V25: 0.128539358273528\n  V26: -0.189114843888824\n  V27: 0.133558376740387\n  V28: -0.0210530534538215\n  Amount: 149.62\n  Class: 0.0\nQuestion: Is this transaction fraudulent? (Yes/No)\nChoices: ['Yes', 'No']\nOutput: No\nGold: 0.0\n\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import os\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\noutput_dir = \"/kaggle/working\"\nos.makedirs(output_dir, exist_ok=True)\n\noutput_file = os.path.join(output_dir, \"Credit_Card_prompt.txt\")\n\nwith open(output_file, \"w\") as f:\n    for i in range(len(german_credit)):\n        sample = german_credit.iloc[i].to_dict()\n        prompt = create_description_based_prompt(sample)\n        f.write(prompt)\n\nprint(f\"Generated prompts saved to: {output_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:42.056877Z","iopub.execute_input":"2025-03-10T15:05:42.057157Z","iopub.status.idle":"2025-03-10T15:05:42.150419Z","shell.execute_reply.started":"2025-03-10T15:05:42.057134Z","shell.execute_reply":"2025-03-10T15:05:42.149633Z"}},"outputs":[{"name":"stdout","text":"Generated prompts saved to: /kaggle/working/Credit_Card_prompt.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# loader = TextLoader(\"../working/Credit_Card_prompt.txt\")\n# documents = loader.load()\n\n# for doc in documents:\n#     print(doc.page_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:42.151175Z","iopub.execute_input":"2025-03-10T15:05:42.151378Z","iopub.status.idle":"2025-03-10T15:05:42.154558Z","shell.execute_reply.started":"2025-03-10T15:05:42.151360Z","shell.execute_reply":"2025-03-10T15:05:42.153737Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"try:\n    nltk.data.find('tokenizers/punkt')\n    nltk.data.find('tokenizers/punkt_tab')\nexcept LookupError:\n    nltk.download('punkt', download_dir='/root/nltk_data')\n    nltk.download('punkt_tab', download_dir='/root/nltk_data')\n    nltk.download('averaged_perceptron_tagger', download_dir='/root/nltk_data')","metadata":{"id":"antVTf890ya2","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:42.155262Z","iopub.execute_input":"2025-03-10T15:05:42.155560Z","iopub.status.idle":"2025-03-10T15:05:42.869222Z","shell.execute_reply.started":"2025-03-10T15:05:42.155533Z","shell.execute_reply":"2025-03-10T15:05:42.868341Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /root/nltk_data...\n[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# drive.mount('/content/drive')","metadata":{"id":"DwdLdPWm03Yj","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:42.870109Z","iopub.execute_input":"2025-03-10T15:05:42.870354Z","iopub.status.idle":"2025-03-10T15:05:42.873535Z","shell.execute_reply.started":"2025-03-10T15:05:42.870328Z","shell.execute_reply":"2025-03-10T15:05:42.872799Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"loader = TextLoader(\"../working/Credit_Card_prompt.txt\")\nfrom datasets import load_dataset\nds = load_dataset(\"LLukas22/fiqa\")\ndocuments = loader.load()\ntexts = [doc.page_content for doc in documents]","metadata":{"id":"_0xp6e2x05qb","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:42.874462Z","iopub.execute_input":"2025-03-10T15:05:42.874807Z","iopub.status.idle":"2025-03-10T15:05:45.495784Z","shell.execute_reply.started":"2025-03-10T15:05:42.874778Z","shell.execute_reply":"2025-03-10T15:05:45.495188Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd532987888248ddab3091d8c5f39940"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.json:   0%|          | 0.00/16.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00fe18cd16df46c1b45426a692100ba1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.json:   0%|          | 0.00/2.82M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fadbba6f2da44a6f934d6c88dc564419"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14511 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0dcf648c17449e8829388cba3f1011a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2561 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1e9491e4c0f4bc8a4d04a4140e07996"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"if len(texts) == 1 and len(texts[0].split('\\n')) > 1:\n    texts = [para.strip() for para in texts[0].split('\\n') if para.strip()]\nelif len(texts) == 1:\n    texts = texts[0].split('.')","metadata":{"id":"4iBAWmue0769","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:45.496558Z","iopub.execute_input":"2025-03-10T15:05:45.496871Z","iopub.status.idle":"2025-03-10T15:05:45.503632Z","shell.execute_reply.started":"2025-03-10T15:05:45.496836Z","shell.execute_reply":"2025-03-10T15:05:45.502772Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"embedding_model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\nembedder = SentenceTransformer(embedding_model_name)\ndoc_embeddings = embedder.encode(texts)\ndoc_embeddings = np.array(doc_embeddings).astype(\"float32\")","metadata":{"id":"JIo3WOzA09qd","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:45.504589Z","iopub.execute_input":"2025-03-10T15:05:45.504854Z","iopub.status.idle":"2025-03-10T15:05:56.150106Z","shell.execute_reply.started":"2025-03-10T15:05:45.504831Z","shell.execute_reply":"2025-03-10T15:05:56.149370Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5ff06c2614d469c93c92db4c4905f70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"883c731e82284fc2be7aee99f5af10a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.89k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de91e095579b4008ac2c954eea3b6b98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f11c048206144da089d9837fc15b1b29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb808f31c5f24cfb8b2af0c9a85a7efc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"917d9db14ce04b4e85c01401542a94f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e844d850494542dfa9feb9a49794bdb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07fd62be87c540e08d10502a4826beed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5578c12b685d4f1aac19ea356fc7fba0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29d88b0499be4340b0c98f5f41a592e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c24ed532d4ce4c489f9570561caecf9f"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"d = doc_embeddings.shape[1]\nindex = faiss.IndexFlatL2(d)\nindex.add(doc_embeddings)","metadata":{"id":"1EKIft6M0_au","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:56.150816Z","iopub.execute_input":"2025-03-10T15:05:56.151090Z","iopub.status.idle":"2025-03-10T15:05:56.157210Z","shell.execute_reply.started":"2025-03-10T15:05:56.151069Z","shell.execute_reply":"2025-03-10T15:05:56.156475Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def analyze_word_frequency(texts, top_n=10):\n    all_words = \" \".join(texts).split()\n    word_freq = Counter(all_words).most_common(top_n)\n\n\n    words, counts = zip(*word_freq)\n    plt.figure(figsize=(10, 5))\n    plt.bar(words, counts)\n    plt.title(\"Top Words Frequency\")\n    plt.xlabel(\"Words\")\n    plt.ylabel(\"Frequency\")\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\n    return f\"Top {top_n} frequent words: {word_freq}\"","metadata":{"id":"p19BpOr20_2d","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:56.158150Z","iopub.execute_input":"2025-03-10T15:05:56.158436Z","iopub.status.idle":"2025-03-10T15:05:56.170723Z","shell.execute_reply.started":"2025-03-10T15:05:56.158407Z","shell.execute_reply":"2025-03-10T15:05:56.170047Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def analyze_clustering(embeddings, texts, n_clusters=3):\n    n_samples = embeddings.shape[0]\n    n_clusters = min(n_clusters, n_samples - 1) if n_samples > 1 else 1\n    if n_samples <= 1:\n        return \"Insufficient samples for clustering (only 1 sample).\"\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n    clusters = kmeans.fit_predict(embeddings)\n    cluster_summary = {}\n    for i in range(n_clusters):\n        cluster_texts = [texts[j] for j in range(len(texts)) if clusters[j] == i]\n        cluster_summary[f\"Cluster {i}\"] = cluster_texts[:2]\n    return f\"Clustering result with {n_clusters} clusters: {cluster_summary}\"\n\ndef analyze_sentiment(texts):\n    sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n    sentiments = []\n    for text in texts:\n        result = sentiment_analyzer(text[:512])\n        sentiments.append((text[:50] + \"...\", result[0]['label'], result[0]['score']))\n    return f\"Sentiment analysis: {sentiments}\"\n\ndef analyze_lda(texts, num_topics=3, passes=10):\n    tokenized_texts = [word_tokenize(text.lower()) for text in texts]\n    dictionary = corpora.Dictionary(tokenized_texts)\n    corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n    lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, passes=passes)\n    topics = lda_model.print_topics()\n    vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n    pyLDAvis.display(vis)\n    return f\"LDA topics with {num_topics} topics: {topics}\"","metadata":{"id":"oRpkXTS81Cbs","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:56.171513Z","iopub.execute_input":"2025-03-10T15:05:56.171802Z","iopub.status.idle":"2025-03-10T15:05:56.189227Z","shell.execute_reply.started":"2025-03-10T15:05:56.171773Z","shell.execute_reply":"2025-03-10T15:05:56.188494Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def parse_analysis_request(user_input):\n    if user_input.lower().startswith(\"analyze:\"):\n        parts = user_input[8:].strip().split()\n        if not parts:\n            return None, None\n        analysis_type = parts[0].lower()\n        params = parts[1:] if len(parts) > 1 else []\n        return analysis_type, params\n    return None, None","metadata":{"id":"hUphLptI1E8U","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:56.190133Z","iopub.execute_input":"2025-03-10T15:05:56.190412Z","iopub.status.idle":"2025-03-10T15:05:56.203023Z","shell.execute_reply.started":"2025-03-10T15:05:56.190383Z","shell.execute_reply":"2025-03-10T15:05:56.202332Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def retrieve_documents(query, k=2):\n    query_embedding = embedder.encode([query])\n    query_embedding = np.array(query_embedding).astype(\"float32\")\n    distances, indices = index.search(query_embedding, k)\n    retrieved = [texts[i] for i in indices[0]]\n    return retrieved","metadata":{"id":"F__g6IsQ1bD-","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:56.203865Z","iopub.execute_input":"2025-03-10T15:05:56.204174Z","iopub.status.idle":"2025-03-10T15:05:56.221899Z","shell.execute_reply.started":"2025-03-10T15:05:56.204145Z","shell.execute_reply":"2025-03-10T15:05:56.220951Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"quantization_config = BitsAndBytesConfig(load_in_4bit=True)\nbase_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", device_map=\"auto\", quantization_config=quantization_config)\nmodel = PeftModel.from_pretrained(base_model, \"FinGPT/fingpt-forecaster_dow30_llama2-7b_lora\")\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")","metadata":{"id":"kaUzJXHQ1coB","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:56.222941Z","iopub.execute_input":"2025-03-10T15:05:56.223314Z","iopub.status.idle":"2025-03-10T15:07:28.848857Z","shell.execute_reply.started":"2025-03-10T15:05:56.223280Z","shell.execute_reply":"2025-03-10T15:07:28.848014Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8a5f58d3ff54276bbe306eca03dfa67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61b56e23107742f3ac1cfd51f93da0e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"270971399c9f4d0493c1571e33b5d998"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14e43cce60b643a8be1b1bc2d19ff0e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f828687443c42a4a79694c6defa28ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"683b3ea0183a4f3a9dcc3fd38dae11f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eca2d9f5f01c460e8335efe6f4a3e939"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/528 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb90d20d84a34f819b88e388bed39315"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/40.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50d78f3540ac44c09beb0aed4851957c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81a954fa4f214128b7ce1ca82bf59c0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e41e36fb3b64049a27d3808e313340e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0bbee454d334291935e7a4a6af10462"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d30a7f5884240b3a6b045eea6bf87ba"}},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"model = model.half()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"id":"Ilvo30pU1eNW","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:07:28.849714Z","iopub.execute_input":"2025-03-10T15:07:28.849928Z","iopub.status.idle":"2025-03-10T15:07:28.886747Z","shell.execute_reply.started":"2025-03-10T15:07:28.849910Z","shell.execute_reply":"2025-03-10T15:07:28.886193Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def qa_chatbot(query, max_new_tokens=150):\n    analysis_type, params = parse_analysis_request(query)\n    context = \"\"\n\n    if analysis_type:\n        try:\n            if analysis_type == \"word_frequency\":\n                top_n = int(params[0]) if params and params[0].isdigit() else 10\n                if top_n <= 0:\n                    raise ValueError(\"top_n must be a positive integer.\")\n                analysis_result = analyze_word_frequency(texts, top_n)\n            elif analysis_type == \"clustering\":\n                n_clusters = int(params[0]) if params and params[0].isdigit() else 3\n                if n_clusters <= 0:\n                    raise ValueError(\"n_clusters must be a positive integer.\")\n                analysis_result = analyze_clustering(doc_embeddings, texts, n_clusters)\n            elif analysis_type == \"sentiment\":\n                analysis_result = analyze_sentiment(texts)\n            elif analysis_type == \"lda\":\n                num_topics = int(params[0]) if params and params[0].isdigit() else 3\n                passes = int(params[1]) if len(params) > 1 and params[1].isdigit() else 10\n                if num_topics <= 0 or passes <= 0:\n                    raise ValueError(\"num_topics and passes must be positive integers.\")\n                analysis_result = analyze_lda(texts, num_topics, passes)\n            else:\n                return f\"Unknown analysis type '{analysis_type}'. Type 'help' for available options.\"\n            context = f\"Analysis Result:\\n{analysis_result}\\n\\n\"\n        except ValueError as e:\n            return f\"Error: {e}\\nPlease provide valid parameters. Type 'help' for options.\"\n\n    if not analysis_type or (analysis_type and \"Error\" not in context):\n        retrieved_docs = retrieve_documents(query if not analysis_type else query.split(\":\", 1)[1].strip())\n        context += \"Retrieved Context:\\n\" + \"\\n\".join(retrieved_docs) + \"\\n\\n\"\n        \n        prompt = (\n            \"You are a multilingual assistant specialized in credit card policies.\\n\"\n            \"Based on the following context, answer the user's question or provide analysis results.\\n\\n\"\n            f\"Context:\\n{context}\\n\"\n            f\"Question: {query if not analysis_type else query.split(':', 1)[1].strip()}\\n\"\n            \"Answer:\"\n        )\n        \n        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n        output_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)\n        output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n        \n        if \"Answer:\" in output_text:\n            answer = output_text.split(\"Answer:\")[-1].strip()\n        else:\n            answer = output_text.strip()\n        \n        return answer","metadata":{"id":"sGH0yJIB1hWS","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:07:28.887427Z","iopub.execute_input":"2025-03-10T15:07:28.887645Z","iopub.status.idle":"2025-03-10T15:07:28.895984Z","shell.execute_reply.started":"2025-03-10T15:07:28.887625Z","shell.execute_reply":"2025-03-10T15:07:28.895168Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"print(\"Multilingual RAG Chatbot (type 'exit' to quit, 'analyze' for dataset analysis, or 'analyze:[type]' for integrated analysis)\")\nprint(\"Available analysis types: 'word_frequency [top_n]', 'clustering [n_clusters]', 'sentiment', 'lda [num_topics] [passes]'\")\nwhile True:\n    user_input = input(\"User: \")\n    if user_input.strip().lower() == \"exit\":\n        print(\"Exiting chat. Goodbye!\")\n        break\n    elif user_input.strip().lower() == \"analyze\":\n        print(\"Please specify your analysis type (e.g., 'word_frequency', 'clustering', 'sentiment', 'lda') or type 'help' for options:\")\n        analysis_type = input(\"Analysis Type: \").strip().lower()\n\n        if analysis_type == \"help\":\n            print(\"Available analysis types:\")\n            print(\"- 'word_frequency [top_n]': Show the top N most frequent words (e.g., 'word_frequency 5').\")\n            print(\"- 'clustering [n_clusters]': Perform clustering with specified number of clusters (e.g., 'clustering 2').\")\n            print(\"- 'sentiment': Analyze sentiment of the text.\")\n            print(\"- 'lda [num_topics] [passes]': Perform LDA topic modeling (e.g., 'lda 3 10').\")\n            print(\"You can also use 'analyze:[type]' in questions for integrated analysis.\")\n            continue\n\n        # 独立分析模式\n        try:\n            params = analysis_type.split()\n            analysis_type = params[0] if params else analysis_type\n\n            if analysis_type == \"word_frequency\":\n                top_n = int(params[1]) if len(params) > 1 else 10\n                if top_n <= 0:\n                    raise ValueError(\"top_n must be a positive integer.\")\n                result = analyze_word_frequency(texts, top_n)\n                print(\"Analysis Results - Top Words:\", result)\n            elif analysis_type == \"clustering\":\n                n_clusters = int(params[1]) if len(params) > 1 else 3\n                if n_clusters <= 0:\n                    raise ValueError(\"n_clusters must be a positive integer.\")\n                result = analyze_clustering(doc_embeddings, texts, n_clusters)\n                print(\"Analysis Results - Clusters:\", result)\n            elif analysis_type == \"sentiment\":\n                result = analyze_sentiment(texts)\n                print(\"Analysis Results - Sentiments:\", result)\n            elif analysis_type == \"lda\":\n                num_topics = int(params[1]) if len(params) > 1 else 3\n                passes = int(params[2]) if len(params) > 2 else 10\n                if num_topics <= 0 or passes <= 0:\n                    raise ValueError(\"num_topics and passes must be positive integers.\")\n                result = analyze_lda(texts, num_topics, passes)\n                print(\"Analysis Results - LDA Topics:\", result)\n            else:\n                print(f\"Unknown analysis type '{analysis_type}'. Type 'help' for available options.\")\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            print(\"Please provide valid parameters. Type 'help' for options.\")\n    else:\n        answer = qa_chatbot(user_input)\n        print(\"Chatbot:\", answer)","metadata":{"id":"KidKRwXr1muk","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:10:38.271340Z","iopub.execute_input":"2025-03-10T15:10:38.271723Z","iopub.status.idle":"2025-03-10T15:14:04.563169Z","shell.execute_reply.started":"2025-03-10T15:10:38.271681Z","shell.execute_reply":"2025-03-10T15:14:04.562392Z"}},"outputs":[{"name":"stdout","text":"Multilingual RAG Chatbot (type 'exit' to quit, 'analyze' for dataset analysis, or 'analyze:[type]' for integrated analysis)\nAvailable analysis types: 'word_frequency [top_n]', 'clustering [n_clusters]', 'sentiment', 'lda [num_topics] [passes]'\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  help\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd8adaf9666f46a58ea95d3ff66f33bf"}},"metadata":{}},{"name":"stdout","text":"Chatbot: \n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  help\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f47624a7a766473991ac2e369a0dd756"}},"metadata":{}},{"name":"stdout","text":"Chatbot: \n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  word_frequency\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b462dad15af4c5f80806a4f7184a5bb"}},"metadata":{}},{"name":"stdout","text":"Chatbot: \n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  help\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2fd8eba9bfd4897b1ba31c05c87d306"}},"metadata":{}},{"name":"stdout","text":"Chatbot: \n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  Available analysis\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bf7d33ebe914523928f0cd2e987dd43"}},"metadata":{}},{"name":"stdout","text":"Chatbot: \n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  exit\n"},{"name":"stdout","text":"Exiting chat. Goodbye!\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}